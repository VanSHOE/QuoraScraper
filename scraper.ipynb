{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "def document_initialised(driver):\n",
    "    return driver.execute_script(\"return initialised\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Post():\n",
    "    def __init__(self, post_element, driver):\n",
    "        self.post_element = post_element\n",
    "        self.driver = driver\n",
    "        self.text = None\n",
    "        self.community_name = None\n",
    "        self.author = None\n",
    "        self.commenters = None\n",
    "        self.upvoters = None\n",
    "        self.upvote_epoch_limit = 100\n",
    "    \n",
    "    def wait(self):\n",
    "        time.sleep(random.randint(1,2))\n",
    "    \n",
    "    def move_into_view(self):\n",
    "        self.driver.execute_script(\"arguments[0].scrollIntoView();\", self.post_element)\n",
    "        self.wait()\n",
    "    \n",
    "    def remove_videos(self):\n",
    "        videos = self.post_element.find_elements(By.CSS_SELECTOR, \"div.q-box.qu-mt--small.standalone_featurable\")\n",
    "        for video in videos:\n",
    "            self.driver.execute_script(\"\"\"\n",
    "            var element = arguments[0];\n",
    "            element.parentNode.removeChild(element);\n",
    "            \"\"\", video)\n",
    "            self.wait()\n",
    "    \n",
    "    def remove_images(self):\n",
    "        images = self.post_element.find_elements(By.TAG_NAME, \"img\")\n",
    "        for image in images:\n",
    "            self.driver.execute_script(\"\"\"\n",
    "            var element = arguments[0];\n",
    "            element.parentNode.removeChild(element);\n",
    "            \"\"\", image)\n",
    "            self.wait()\n",
    "    \n",
    "    def click(self):\n",
    "        # click on the post to get expanded view\n",
    "        actions = webdriver.ActionChains(driver)\n",
    "        # click on top\n",
    "        actions.move_to_element_with_offset(self.post_element, 0, self.post_element.size[\"height\"]/2-10)\n",
    "        actions.click()\n",
    "        actions.perform()\n",
    "        self.wait()\n",
    "    \n",
    "    def scrape_text(self):\n",
    "        WebDriverWait(self.driver, timeout=10).until(lambda d: d.find_element(By.CSS_SELECTOR,\".q-text.qu-display--block.qu-wordBreak--break-word.qu-textAlign--start\")) # this is the p tag containing the text\n",
    "        \n",
    "        # get the text from the p tag\n",
    "        self.text = self.driver.find_element(By.CSS_SELECTOR, \".q-text.qu-display--block.qu-wordBreak--break-word.qu-textAlign--start\").text\n",
    "        self.wait()\n",
    "    \n",
    "    def scrape_community_name(self):\n",
    "        # get the community name\n",
    "        WebDriverWait(self.driver, timeout=10).until(lambda d: d.find_element(By.CSS_SELECTOR, \".q-text.puppeteer_test_tribe_name\"))\n",
    "        self.community_name = driver.find_element(By.CSS_SELECTOR, \".q-text.puppeteer_test_tribe_name\").text\n",
    "        self.wait()\n",
    "    \n",
    "    def scrape_author(self):\n",
    "        # get all the links in the post\n",
    "        all_links = self.post_element.find_elements(By.XPATH, \".//a[@href]\")\n",
    "        \n",
    "        # get the link to the profile. The href should contain the word profile\n",
    "        profile_link = \"\"\n",
    "        for link in all_links:\n",
    "            if \"profile\" in link.get_attribute(\"href\"):\n",
    "                profile_link = link.get_attribute(\"href\")\n",
    "                break\n",
    "        self.author = profile_link\n",
    "    \n",
    "    def scrape_upvotes(self):\n",
    "        # find upvote text and click on it\n",
    "        try:\n",
    "            upvote_text = self.post_element.find_element(By.XPATH, \"//*[text()='View upvotes']\")\n",
    "            upvote_text.click()\n",
    "\n",
    "            # wait for the upvote popup to load \n",
    "            time.sleep(2)\n",
    "\n",
    "            # get the upvote popup\n",
    "            upvote_popup = self.driver.find_element(By.CSS_SELECTOR, \"div.q-box.qu-overflowY--auto.qu-display--flex.qu-flexDirection--column.ScrollBox___StyledBox-sc-1t8bc7j-0.eEjJKQ\")\n",
    "            \n",
    "            # scroll the modal to the bottom to load next batch of upvoters until the end\n",
    "            epoch = 0\n",
    "            last_count = 0\n",
    "            curr_count = 0\n",
    "            error_count = 3\n",
    "            while epoch < self.upvote_epoch_limit:\n",
    "                try:\n",
    "                    self.driver.execute_script(\"arguments[0].scrollTo(0, arguments[0].scrollHeight)\", upvote_popup)\n",
    "                    time.sleep(4)\n",
    "                    \n",
    "                    if(epoch == 0):\n",
    "                        last_count = len(upvote_popup.find_elements(By.XPATH, \".//a[@href]\"))\n",
    "                        curr_count = last_count\n",
    "                        epoch += 1\n",
    "                        continue\n",
    "                    \n",
    "                    # check if we got more upvoters, if not, break\n",
    "                    curr_count = len(upvote_popup.find_elements(By.XPATH, \".//a[@href]\"))\n",
    "                    if(curr_count == last_count):\n",
    "                        if(error_count == 0):\n",
    "                            break\n",
    "                        else:\n",
    "                            error_count -= 1\n",
    "                    else:\n",
    "                        last_count = curr_count\n",
    "\n",
    "                    epoch += 1\n",
    "                except:\n",
    "                    break\n",
    "            \n",
    "            # get all the links in the popup\n",
    "            upvoter_links = upvote_popup.find_elements(By.XPATH, \".//a[@href]\")\n",
    "            upvoter_links = [link.get_attribute(\"href\") for link in upvoter_links if \"profile\" in link.get_attribute(\"href\")]\n",
    "            upvoter_links = list(set(upvoter_links))\n",
    "            \n",
    "            time.sleep(random.randint(5,10))\n",
    "\n",
    "            # close the popup\n",
    "            close_button = self.driver.find_element(By.CLASS_NAME, \"q-click-wrapper\")\n",
    "            close_button.click()\n",
    "\n",
    "            self.wait()\n",
    "        except:\n",
    "            upvoter_links = []\n",
    "        self.upvoters = upvoter_links\n",
    "\n",
    "    def scrape_comments(self):\n",
    "        comments_container = self.post_element.find_element(By.CLASS_NAME, \"comment_and_ad_container\")\n",
    "        comments_container.click()\n",
    "        \n",
    "        # now, comments container is expanded. Click on view more comments\n",
    "        self.wait()\n",
    "        \n",
    "        try:\n",
    "            view_more_comments = comments_container.find_element(By.XPATH, \"//*[text()='View more comments']\")\n",
    "            self.wait()\n",
    "            view_more_comments.click()\n",
    "            self.wait()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # now get the profile links of all the commenters        \n",
    "        comment_links = comments_container.find_elements(By.XPATH, \".//a[@href]\")\n",
    "        comment_links = [link.get_attribute(\"href\") for link in comment_links if \"profile\" in link.get_attribute(\"href\")]\n",
    "        comment_links = list(set(comment_links))\n",
    "        \n",
    "        # remove the profile link of the post author\n",
    "        self.commenters = [link for link in comment_links if link != self.author]\n",
    "        \n",
    "        self.wait()\n",
    "    \n",
    "    def master_scrape(self):\n",
    "        self.move_into_view()\n",
    "        self.remove_videos()\n",
    "        self.click()\n",
    "        self.remove_images()\n",
    "        self.scrape_community_name()\n",
    "        self.scrape_author()\n",
    "        self.scrape_text()\n",
    "        self.scrape_upvotes()\n",
    "        self.scrape_comments()        \n",
    "\n",
    "    def get_post_details(self):\n",
    "        return {\n",
    "            \"text\": self.text,\n",
    "            \"community_name\": self.community_name,\n",
    "            \"author\": self.author,\n",
    "            \"commenters\": self.commenters,\n",
    "            \"upvoters\": self.upvoters\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostScraper():\n",
    "    def __init__(self, driver, search_query, total_post_count):\n",
    "        self.driver = driver\n",
    "        self.scraped_posts = []\n",
    "        self.visible_posts = []\n",
    "        self.search_query = search_query\n",
    "        \n",
    "        self.total_post_count = total_post_count\n",
    "        self.scraped_post_count = 0\n",
    "        self.epoch = 0\n",
    "    \n",
    "    def wait(self):\n",
    "        time.sleep(random.randint(1, 2))\n",
    "    \n",
    "    def open_search_page(self):\n",
    "        while(len(self.visible_posts) == 0):\n",
    "            try:\n",
    "                search_url = \"https://www.quora.com/search?q=\"+self.search_query+\"&type=post\"\n",
    "                self.driver.get(search_url)\n",
    "                self.wait()\n",
    "                self.get_new_posts()\n",
    "            except:\n",
    "                print(\"error opening search page\")\n",
    "                self.wait()\n",
    "    \n",
    "    def check_upvote_popup(self):\n",
    "        # get the upvote popup\n",
    "        upvote_popup = self.driver.find_elements(By.CSS_SELECTOR, \"div.q-box.qu-overflowY--auto.qu-display--flex.qu-flexDirection--column.ScrollBox___StyledBox-sc-1t8bc7j-0.eEjJKQ\")\n",
    "        if len(upvote_popup) > 0:\n",
    "            # close the popup\n",
    "            close_button = self.driver.find_element(By.CLASS_NAME, \"q-click-wrapper\")\n",
    "            close_button.click()\n",
    "            self.wait()\n",
    "    \n",
    "    def scrape_single_post(self, post):\n",
    "        # scroll the page till next post is visible and wait for 2 seconds\n",
    "        try:\n",
    "            postElement = Post(post, self.driver)\n",
    "            postElement.master_scrape()\n",
    "            self.scraped_posts.append(postElement.get_post_details())\n",
    "        except:\n",
    "            print(\"error scraping post\")\n",
    "            self.check_upvote_popup()\n",
    "            self.wait()\n",
    "    \n",
    "    def scrape_visible_posts(self):\n",
    "        for post in self.visible_posts:\n",
    "            self.scrape_single_post(post)\n",
    "            self.scraped_post_count += 1\n",
    "            self.remove_post(post)\n",
    "    \n",
    "    def remove_post(self, post):\n",
    "        self.driver.execute_script(\"\"\"\n",
    "        var element = arguments[0];\n",
    "        element.parentNode.removeChild(element);\n",
    "        \"\"\", post)\n",
    "        self.wait()\n",
    "    \n",
    "    def get_new_posts(self):\n",
    "        # get all the posts on the page\n",
    "        try:\n",
    "            all_posts = driver.find_elements(By.CSS_SELECTOR, \".q-box.qu-borderBottom.qu-px--medium.qu-pt--medium\")\n",
    "            self.visible_posts = all_posts\n",
    "        except:\n",
    "            self.wait()\n",
    "    \n",
    "    def run(self):\n",
    "        self.open_search_page()\n",
    "        while(self.scraped_post_count < self.total_post_count):\n",
    "            self.get_new_posts()\n",
    "            self.scrape_visible_posts()\n",
    "            self.epoch += 1\n",
    "            self.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraper = PostScraper(driver, \"ronaldo\", 100)\n",
    "# scraper.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserScraper():\n",
    "    def __init__(self, driver, profile_link):\n",
    "        self.driver = driver\n",
    "        self.profile_link = profile_link\n",
    "        self.followers = []\n",
    "        self.following = []\n",
    "        self.creds = []\n",
    "        self.epochs = 100\n",
    "        self.error_margin = 3\n",
    "        self.driver.get(self.profile_link)\n",
    "    \n",
    "    def wait(self):\n",
    "        time.sleep(random.randint(1,2))\n",
    "        \n",
    "    def scrape_linked_users(self, type):\n",
    "        # find upvote text and click on it\n",
    "        try:\n",
    "            upvote_text = self.driver.find_elements(By.CSS_SELECTOR, \".q-text.qu-dynamicFontSize--small.qu-color--gray\")[type]\n",
    "            \n",
    "            upvote_text.click()\n",
    "\n",
    "            # wait for the upvote popup to load \n",
    "            time.sleep(2)\n",
    "\n",
    "            # get the upvote popup\n",
    "            upvote_popup = self.driver.find_element(By.CSS_SELECTOR, \"div.q-box.qu-overflowY--auto.qu-display--flex.qu-flexDirection--column.ScrollBox___StyledBox-sc-1t8bc7j-0.eEjJKQ\")\n",
    "            \n",
    "            # scroll the modal to the bottom to load next batch of upvoters until the end\n",
    "            epoch = 0\n",
    "            last_count = 0\n",
    "            curr_count = 0\n",
    "            error_count = 3\n",
    "            while epoch < self.epochs:\n",
    "                try:\n",
    "                    self.driver.execute_script(\"arguments[0].scrollTo(0, arguments[0].scrollHeight)\", upvote_popup)\n",
    "                    time.sleep(4)\n",
    "                    \n",
    "                    if(epoch == 0):\n",
    "                        last_count = len(upvote_popup.find_elements(By.XPATH, \".//a[@href]\"))\n",
    "                        curr_count = last_count\n",
    "                        epoch += 1\n",
    "                        continue\n",
    "                    \n",
    "                    # check if we got more upvoters, if not, break\n",
    "                    curr_count = len(upvote_popup.find_elements(By.XPATH, \".//a[@href]\"))\n",
    "                    if(curr_count == last_count):\n",
    "                        if(error_count == 0):\n",
    "                            break\n",
    "                        else:\n",
    "                            error_count -= 1\n",
    "                    else:\n",
    "                        last_count = curr_count\n",
    "\n",
    "                    epoch += 1\n",
    "                except:\n",
    "                    break\n",
    "            \n",
    "            # get all the links in the popup\n",
    "            upvoter_links = upvote_popup.find_elements(By.XPATH, \".//a[@href]\")\n",
    "            upvoter_links = [link.get_attribute(\"href\") for link in upvoter_links if \"profile\" in link.get_attribute(\"href\")]\n",
    "            upvoter_links = list(set(upvoter_links))\n",
    "            \n",
    "            time.sleep(random.randint(5,10))\n",
    "\n",
    "            # close the popup\n",
    "            close_button = self.driver.find_element(By.CLASS_NAME, \"q-click-wrapper\")\n",
    "            close_button.click()\n",
    "\n",
    "            self.wait()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            upvoter_links = []\n",
    "        print(len(upvoter_links))\n",
    "        if type == 0:\n",
    "            self.followers = upvoter_links\n",
    "        else:\n",
    "            self.following = upvoter_links\n",
    "    \n",
    "    def scrape_credentials(self):\n",
    "        main_div = self.driver.find_elements(By.CSS_SELECTOR, \".q-text.qu-dynamicFontSize--small.qu-mt--small\")\n",
    "        for div in main_div:\n",
    "            self.creds.append(div.text)\n",
    "    \n",
    "    def save_to_csv(self):\n",
    "        with open(\"users/users.csv\", \"a+\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([self.profile_link, self.followers, self.following, self.creds])\n",
    "    \n",
    "    def run(self):\n",
    "        self.scrape_linked_users(0)\n",
    "        self.scrape_linked_users(1)\n",
    "        self.scrape_credentials()\n",
    "        self.save_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper = UserScraper(driver, \"https://www.quora.com/profile/Ripam-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310\n",
      "132\n"
     ]
    }
   ],
   "source": [
    "scraper.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
